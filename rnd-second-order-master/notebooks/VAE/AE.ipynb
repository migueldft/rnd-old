{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_parquet(\"../dataset.parquet\")\n",
    "    categorical_columns = ['partner', 'device', 'gender', 'state', 'channel']\n",
    "    feature_columns = [\n",
    "        'channel', 'partner', 'device', 'age', 'gender', 'state', 'has_marketplace', \n",
    "        'has_crossdocking', 'has_private_label', 'has_brands', 'gmv', \n",
    "        'fst_sale_in_black_friday_days', 'snd_sale_in_black_friday_days'\n",
    "    ]\n",
    "\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "    df = df.loc[df.waiting_time > 0]\n",
    "\n",
    "    features = [c for c in df.columns if any([c.startswith(x) for x in feature_columns])]\n",
    "    X = df.loc[:, features].copy()\n",
    "    y = df.loc[:, 'has_second_sale_within_year'].copy()\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    qt = QuantileTransformer()\n",
    "    qt.fit(X_train.loc[:, [\"age\", \"gmv\"]])\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        X_train.loc[:, [\"age\", \"gmv\"]] = qt.transform(X_train.loc[:, [\"age\", \"gmv\"]])\n",
    "        X_test.loc[:, [\"age\", \"gmv\"]] = qt.transform(X_test.loc[:, [\"age\", \"gmv\"]])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples, shape_dim = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 577499 samples, validate on 64167 samples\n",
      "Epoch 1/10\n",
      "577499/577499 [==============================] - 11s 20us/sample - loss: 0.0707 - mae: 0.0465 - val_loss: 0.0138 - val_mae: 0.0022\n",
      "Epoch 2/10\n",
      "577499/577499 [==============================] - 11s 19us/sample - loss: 0.0131 - mae: 0.0015 - val_loss: 0.0127 - val_mae: 0.0010\n",
      "Epoch 3/10\n",
      "577499/577499 [==============================] - 11s 19us/sample - loss: 0.0126 - mae: 9.6733e-04 - val_loss: 0.0125 - val_mae: 8.3383e-04\n",
      "Epoch 4/10\n",
      "577499/577499 [==============================] - 11s 19us/sample - loss: 0.0125 - mae: 8.1975e-04 - val_loss: 0.0124 - val_mae: 7.4667e-04\n",
      "Epoch 5/10\n",
      "577499/577499 [==============================] - 11s 18us/sample - loss: 0.0125 - mae: 7.2649e-04 - val_loss: 0.0124 - val_mae: 6.2411e-04\n",
      "Epoch 6/10\n",
      "577499/577499 [==============================] - 11s 18us/sample - loss: 0.0124 - mae: 6.2685e-04 - val_loss: 0.0124 - val_mae: 5.3258e-04\n",
      "Epoch 7/10\n",
      "577499/577499 [==============================] - 11s 18us/sample - loss: 0.0124 - mae: 5.4283e-04 - val_loss: 0.0124 - val_mae: 8.4892e-04\n",
      "Epoch 8/10\n",
      "577499/577499 [==============================] - 11s 19us/sample - loss: 0.0124 - mae: 4.7813e-04 - val_loss: 0.0123 - val_mae: 3.7680e-04\n",
      "Epoch 9/10\n",
      "577499/577499 [==============================] - 11s 18us/sample - loss: 0.0123 - mae: 4.2985e-04 - val_loss: 0.0123 - val_mae: 5.0357e-04\n",
      "Epoch 10/10\n",
      "577499/577499 [==============================] - 11s 18us/sample - loss: 0.0123 - mae: 4.0122e-04 - val_loss: 0.0123 - val_mae: 4.9936e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb29f29c320>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = k.Input(shape=(shape_dim,))\n",
    "\n",
    "pos_encoder = k.models.Sequential([\n",
    "    k.layers.Dense(128, activation='selu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dense(32, activation='selu'),\n",
    "    k.layers.BatchNormalization()\n",
    "])\n",
    "\n",
    "pos_decoder = k.models.Sequential([\n",
    "    k.layers.Dense(128, activation='selu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dense(shape_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "pos_ae = k.models.Model(inputs=inputs, outputs=pos_decoder(pos_encoder(inputs)))\n",
    "pos_ae.compile(\n",
    "    optimizer=k.optimizers.Nadam(), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "pos_ae.fit(\n",
    "    X_train.loc[y_train == 0], \n",
    "    X_train.loc[y_train == 0], \n",
    "    validation_split=0.1,\n",
    "    batch_size=512,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 195819 samples, validate on 21758 samples\n",
      "Epoch 1/10\n",
      "195819/195819 [==============================] - 4s 21us/sample - loss: 0.1776 - mae: 0.1286 - val_loss: 0.0306 - val_mae: 0.0178\n",
      "Epoch 2/10\n",
      "195819/195819 [==============================] - 4s 19us/sample - loss: 0.0191 - mae: 0.0069 - val_loss: 0.0168 - val_mae: 0.0050\n",
      "Epoch 3/10\n",
      "195819/195819 [==============================] - 3s 16us/sample - loss: 0.0150 - mae: 0.0031 - val_loss: 0.0144 - val_mae: 0.0026\n",
      "Epoch 4/10\n",
      "195819/195819 [==============================] - 4s 18us/sample - loss: 0.0139 - mae: 0.0020 - val_loss: 0.0136 - val_mae: 0.0017\n",
      "Epoch 5/10\n",
      "195819/195819 [==============================] - 4s 19us/sample - loss: 0.0134 - mae: 0.0015 - val_loss: 0.0132 - val_mae: 0.0013\n",
      "Epoch 6/10\n",
      "195819/195819 [==============================] - 4s 20us/sample - loss: 0.0131 - mae: 0.0012 - val_loss: 0.0130 - val_mae: 0.0011\n",
      "Epoch 7/10\n",
      "195819/195819 [==============================] - 4s 20us/sample - loss: 0.0129 - mae: 0.0011 - val_loss: 0.0129 - val_mae: 9.8490e-04\n",
      "Epoch 8/10\n",
      "195819/195819 [==============================] - 4s 22us/sample - loss: 0.0129 - mae: 9.7892e-04 - val_loss: 0.0128 - val_mae: 8.9165e-04\n",
      "Epoch 9/10\n",
      "195819/195819 [==============================] - 4s 20us/sample - loss: 0.0128 - mae: 9.0589e-04 - val_loss: 0.0127 - val_mae: 8.2614e-04\n",
      "Epoch 10/10\n",
      "195819/195819 [==============================] - 4s 20us/sample - loss: 0.0127 - mae: 8.5871e-04 - val_loss: 0.0127 - val_mae: 8.6721e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb22037fba8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = k.Input(shape=(shape_dim,))\n",
    "\n",
    "neg_encoder = k.models.Sequential([\n",
    "    k.layers.Dense(128, activation='selu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dense(32, activation='selu'),\n",
    "    k.layers.BatchNormalization()\n",
    "])\n",
    "\n",
    "neg_decoder = k.models.Sequential([\n",
    "    k.layers.Dense(128, activation='selu'),\n",
    "    k.layers.BatchNormalization(),\n",
    "    k.layers.Dense(shape_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "neg_ae = k.models.Model(inputs=inputs, outputs=neg_decoder(neg_encoder(inputs)))\n",
    "neg_ae.compile(\n",
    "    optimizer=k.optimizers.Nadam(), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "neg_ae.fit(\n",
    "    X_train.loc[y_train == 1], \n",
    "    X_train.loc[y_train == 1], \n",
    "    validation_split=0.1,\n",
    "    batch_size=512,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos = pos_encoder.predict(X_train)\n",
    "X_train_neg = neg_encoder.predict(X_train)\n",
    "X_train_rec = pd.np.c_[X_train_pos, X_train_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pos = pos_encoder.predict(X_test)\n",
    "X_test_neg = neg_encoder.predict(X_test)\n",
    "X_test_rec = pd.np.c_[X_test_pos, X_test_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_train = pd.np.abs(X_train_pos - X_train_neg).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    859243.000000\n",
       "mean          1.128097\n",
       "std           0.169506\n",
       "min           0.578930\n",
       "25%           1.004107\n",
       "50%           1.113032\n",
       "75%           1.233748\n",
       "max           2.194006\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(delta_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = pd.np.linspace(0.57, 2.2, 101)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xscale('log')\n",
    "ax.hist(delta_train[y_train == 0], bins=bins, alpha=0.5, density=True)\n",
    "ax.hist(delta_train[y_train == 1], bins=bins, alpha=0.5, density=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = k.Input(shape=(shape_dim,))\n",
    "x = k.layers.Dense(64, activation='selu')(inputs)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dense(64, activation='selu')(x)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dense(64, activation='selu')(x)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "clf_simple = k.models.Model(inputs=inputs, outputs=x)\n",
    "clf_simple.compile(optimizer=k.optimizers.Nadam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 773318 samples, validate on 85925 samples\n",
      "Epoch 1/5\n",
      "773318/773318 [==============================] - 10s 13us/sample - loss: 0.3755 - accuracy: 0.8405 - val_loss: 0.3589 - val_accuracy: 0.8495\n",
      "Epoch 2/5\n",
      "773318/773318 [==============================] - 9s 12us/sample - loss: 0.3544 - accuracy: 0.8516 - val_loss: 0.3568 - val_accuracy: 0.8509\n",
      "Epoch 3/5\n",
      "773318/773318 [==============================] - 10s 12us/sample - loss: 0.3523 - accuracy: 0.8524 - val_loss: 0.3568 - val_accuracy: 0.8501\n",
      "Epoch 4/5\n",
      "773318/773318 [==============================] - 10s 13us/sample - loss: 0.3513 - accuracy: 0.8527 - val_loss: 0.3560 - val_accuracy: 0.8508\n",
      "Epoch 5/5\n",
      "773318/773318 [==============================] - 10s 13us/sample - loss: 0.3508 - accuracy: 0.8528 - val_loss: 0.3542 - val_accuracy: 0.8522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb13f16b390>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_simple.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.1,\n",
    "    batch_size=512,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = k.Input(shape=(2 * 32,))\n",
    "x = k.layers.Dense(64, activation='selu')(inputs)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dense(64, activation='selu')(x)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dense(64, activation='selu')(x)\n",
    "x = k.layers.BatchNormalization()(x)\n",
    "x = k.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "clf = k.models.Model(inputs=inputs, outputs=x)\n",
    "clf.compile(optimizer=k.optimizers.Nadam(), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 773318 samples, validate on 85925 samples\n",
      "Epoch 1/5\n",
      "773318/773318 [==============================] - 7s 9us/sample - loss: 0.3834 - accuracy: 0.8373 - val_loss: 0.3667 - val_accuracy: 0.8469\n",
      "Epoch 2/5\n",
      "773318/773318 [==============================] - 6s 8us/sample - loss: 0.3585 - accuracy: 0.8500 - val_loss: 0.3638 - val_accuracy: 0.8485\n",
      "Epoch 3/5\n",
      "773318/773318 [==============================] - 6s 8us/sample - loss: 0.3553 - accuracy: 0.8512 - val_loss: 0.3588 - val_accuracy: 0.8508\n",
      "Epoch 4/5\n",
      "773318/773318 [==============================] - 6s 8us/sample - loss: 0.3537 - accuracy: 0.8520 - val_loss: 0.3551 - val_accuracy: 0.8509\n",
      "Epoch 5/5\n",
      "773318/773318 [==============================] - 7s 9us/sample - loss: 0.3524 - accuracy: 0.8524 - val_loss: 0.3566 - val_accuracy: 0.8501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0c2195160>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train_rec,\n",
    "    y_train,\n",
    "    validation_split=0.1,\n",
    "    batch_size=512,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368248/368248 [==============================] - 7s 20us/sample - loss: 0.3531 - accuracy: 0.8514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3530589864562749, 0.8513719]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_simple.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368248/368248 [==============================] - 8s 20us/sample - loss: 0.3561 - accuracy: 0.8501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3561269393872294, 0.8500603]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.evaluate(X_test_rec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
