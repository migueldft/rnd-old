{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize, QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycm import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, AlphaDropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "from autoencoders import make_conditional_autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = pd.read_parquet(\"../dataset.parquet\")\n",
    "    categorical_columns = ['partner', 'device', 'gender', 'state', 'channel']\n",
    "    feature_columns = [\n",
    "        'channel', 'partner', 'device', 'age', 'gender', 'state', 'has_marketplace', \n",
    "        'has_crossdocking', 'has_private_label', 'has_brands', 'gmv', \n",
    "        'fst_sale_in_black_friday_days', 'snd_sale_in_black_friday_days'\n",
    "    ]\n",
    "\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "    df = df.loc[df.waiting_time > 0]\n",
    "\n",
    "    features = [c for c in df.columns if any([c.startswith(x) for x in feature_columns])]\n",
    "    X = df.loc[:, features].copy()\n",
    "    y = df.loc[:, 'has_second_sale_within_year'].copy()\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    qt = QuantileTransformer()\n",
    "    qt.fit(X_train.loc[:, [\"age\", \"gmv\"]])\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        X_train.loc[:, [\"age\", \"gmv\"]] = qt.transform(X_train.loc[:, [\"age\", \"gmv\"]])\n",
    "        X_test.loc[:, [\"age\", \"gmv\"]] = qt.transform(X_test.loc[:, [\"age\", \"gmv\"]])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples, shape_dim = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu_encoder = Sequential([\n",
    "    Dense(16, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(8, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(4, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(2, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "])\n",
    "\n",
    "log_sigma_encoder = Sequential([\n",
    "    Dense(64, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(32, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(8, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(4, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(2, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "])\n",
    "\n",
    "decoder = Sequential([\n",
    "    Dense(4, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(8, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation=\"selu\", kernel_initializer='orthogonal'),\n",
    "    BatchNormalization(),\n",
    "    Dense(shape_dim, activation=\"sigmoid\", kernel_initializer='orthogonal')\n",
    "])\n",
    "\n",
    "\n",
    "vae = make_conditional_autoencoder(\n",
    "    mu_encoder, log_sigma_encoder, decoder, shape_dim, Nadam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "859243/859243 [==============================] - 33s 39us/sample - loss: 9.0443 - reconstruction_loss: 0.1789 - representation_loss: 8.8654\n",
      "Epoch 2/400\n",
      "859243/859243 [==============================] - 33s 39us/sample - loss: 9.0434 - reconstruction_loss: 0.1789 - representation_loss: 8.8645\n",
      "Epoch 3/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0470 - reconstruction_loss: 0.1788 - representation_loss: 8.8682\n",
      "Epoch 4/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0450 - reconstruction_loss: 0.1788 - representation_loss: 8.8662\n",
      "Epoch 5/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0458 - reconstruction_loss: 0.1788 - representation_loss: 8.8670\n",
      "Epoch 6/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0444 - reconstruction_loss: 0.1788 - representation_loss: 8.8656\n",
      "Epoch 7/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1788 - representation_loss: 8.8659\n",
      "Epoch 8/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0459 - reconstruction_loss: 0.1787 - representation_loss: 8.8671\n",
      "Epoch 9/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0450 - reconstruction_loss: 0.1787 - representation_loss: 8.8663\n",
      "Epoch 10/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1787 - representation_loss: 8.8662\n",
      "Epoch 11/400\n",
      "859243/859243 [==============================] - 31s 37us/sample - loss: 9.0443 - reconstruction_loss: 0.1787 - representation_loss: 8.8655\n",
      "Epoch 12/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0439 - reconstruction_loss: 0.1787 - representation_loss: 8.8652\n",
      "Epoch 13/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0448 - reconstruction_loss: 0.1787 - representation_loss: 8.8661\n",
      "Epoch 14/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0429 - reconstruction_loss: 0.1787 - representation_loss: 8.8643\n",
      "Epoch 15/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0438 - reconstruction_loss: 0.1787 - representation_loss: 8.8651\n",
      "Epoch 16/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1787 - representation_loss: 8.8649\n",
      "Epoch 17/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0437 - reconstruction_loss: 0.1787 - representation_loss: 8.8650\n",
      "Epoch 18/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1787 - representation_loss: 8.8663\n",
      "Epoch 19/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1786 - representation_loss: 8.8663\n",
      "Epoch 20/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0444 - reconstruction_loss: 0.1787 - representation_loss: 8.8657\n",
      "Epoch 21/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 22/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0433 - reconstruction_loss: 0.1787 - representation_loss: 8.8647\n",
      "Epoch 23/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 24/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 25/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0450 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 26/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 27/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8662\n",
      "Epoch 28/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 29/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 30/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0429 - reconstruction_loss: 0.1786 - representation_loss: 8.8643\n",
      "Epoch 31/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 32/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8669\n",
      "Epoch 33/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 34/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 35/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 36/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 37/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0444 - reconstruction_loss: 0.1786 - representation_loss: 8.8658\n",
      "Epoch 38/400\n",
      "859243/859243 [==============================] - 31s 37us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 39/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 40/400\n",
      "859243/859243 [==============================] - 32s 38us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 41/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 42/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 43/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0459 - reconstruction_loss: 0.1786 - representation_loss: 8.8673\n",
      "Epoch 44/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 45/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0430 - reconstruction_loss: 0.1786 - representation_loss: 8.8644\n",
      "Epoch 46/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8662\n",
      "Epoch 47/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8668\n",
      "Epoch 48/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0429 - reconstruction_loss: 0.1786 - representation_loss: 8.8643\n",
      "Epoch 49/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 50/400\n",
      "859243/859243 [==============================] - 33s 38us/sample - loss: 9.0435 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 51/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 52/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0459 - reconstruction_loss: 0.1786 - representation_loss: 8.8673\n",
      "Epoch 53/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0433 - reconstruction_loss: 0.1786 - representation_loss: 8.8648\n",
      "Epoch 54/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 55/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0442 - reconstruction_loss: 0.1786 - representation_loss: 8.8656\n",
      "Epoch 56/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8661\n",
      "Epoch 57/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 58/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 59/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 60/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 61/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 62/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8661\n",
      "Epoch 63/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 64/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 65/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0462 - reconstruction_loss: 0.1786 - representation_loss: 8.8676\n",
      "Epoch 66/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0443 - reconstruction_loss: 0.1786 - representation_loss: 8.8657\n",
      "Epoch 67/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0451 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 68/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0450 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 69/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 70/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 71/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 72/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0443 - reconstruction_loss: 0.1786 - representation_loss: 8.8657\n",
      "Epoch 73/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 74/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0442 - reconstruction_loss: 0.1786 - representation_loss: 8.8656\n",
      "Epoch 75/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8662\n",
      "Epoch 76/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 77/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 78/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8656\n",
      "Epoch 79/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 80/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 81/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 82/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 83/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 84/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8663\n",
      "Epoch 85/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0428 - reconstruction_loss: 0.1786 - representation_loss: 8.8642\n",
      "Epoch 86/400\n",
      "859243/859243 [==============================] - 31s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 87/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 88/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0432 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 89/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0432 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 90/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0430 - reconstruction_loss: 0.1786 - representation_loss: 8.8644\n",
      "Epoch 91/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 92/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 93/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8671\n",
      "Epoch 94/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0465 - reconstruction_loss: 0.1786 - representation_loss: 8.8679\n",
      "Epoch 95/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8645\n",
      "Epoch 96/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8662\n",
      "Epoch 97/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8661\n",
      "Epoch 98/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0435 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 99/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8662\n",
      "Epoch 100/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8669\n",
      "Epoch 101/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 102/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 103/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8645\n",
      "Epoch 104/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 105/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0442 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 106/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 107/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0449 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 108/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 109/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8669\n",
      "Epoch 110/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8662\n",
      "Epoch 111/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 112/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 113/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0433 - reconstruction_loss: 0.1786 - representation_loss: 8.8648\n",
      "Epoch 114/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8645\n",
      "Epoch 115/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0454 - reconstruction_loss: 0.1786 - representation_loss: 8.8668\n",
      "Epoch 116/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 117/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0442 - reconstruction_loss: 0.1786 - representation_loss: 8.8656\n",
      "Epoch 118/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 119/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0444 - reconstruction_loss: 0.1786 - representation_loss: 8.8658\n",
      "Epoch 120/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0434 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 121/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 122/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 123/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 124/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 125/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0450 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 126/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0444 - reconstruction_loss: 0.1786 - representation_loss: 8.8658\n",
      "Epoch 127/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0450 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 128/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 129/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0434 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 130/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 131/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0426 - reconstruction_loss: 0.1786 - representation_loss: 8.8640\n",
      "Epoch 132/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0454 - reconstruction_loss: 0.1786 - representation_loss: 8.8668\n",
      "Epoch 133/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0454 - reconstruction_loss: 0.1786 - representation_loss: 8.8668\n",
      "Epoch 134/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 135/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 136/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8663\n",
      "Epoch 137/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0432 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 138/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0451 - reconstruction_loss: 0.1786 - representation_loss: 8.8665\n",
      "Epoch 139/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0442 - reconstruction_loss: 0.1785 - representation_loss: 8.8656\n",
      "Epoch 140/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0459 - reconstruction_loss: 0.1786 - representation_loss: 8.8673\n",
      "Epoch 141/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 142/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 143/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 144/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8669\n",
      "Epoch 145/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 146/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0430 - reconstruction_loss: 0.1786 - representation_loss: 8.8644\n",
      "Epoch 147/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0464 - reconstruction_loss: 0.1786 - representation_loss: 8.8678\n",
      "Epoch 148/400\n",
      "859243/859243 [==============================] - 31s 37us/sample - loss: 9.0423 - reconstruction_loss: 0.1786 - representation_loss: 8.8638\n",
      "Epoch 149/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8656\n",
      "Epoch 150/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1785 - representation_loss: 8.8660\n",
      "Epoch 151/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1785 - representation_loss: 8.8659\n",
      "Epoch 152/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 153/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 154/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0443 - reconstruction_loss: 0.1786 - representation_loss: 8.8657\n",
      "Epoch 155/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0429 - reconstruction_loss: 0.1786 - representation_loss: 8.8644\n",
      "Epoch 156/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0457 - reconstruction_loss: 0.1786 - representation_loss: 8.8671\n",
      "Epoch 157/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 158/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0434 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 159/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0429 - reconstruction_loss: 0.1786 - representation_loss: 8.8643\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8661\n",
      "Epoch 161/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0434 - reconstruction_loss: 0.1786 - representation_loss: 8.8648\n",
      "Epoch 162/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 163/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8652\n",
      "Epoch 164/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0449 - reconstruction_loss: 0.1786 - representation_loss: 8.8663\n",
      "Epoch 165/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0458 - reconstruction_loss: 0.1786 - representation_loss: 8.8672\n",
      "Epoch 166/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0434 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 167/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 168/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8662\n",
      "Epoch 169/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0449 - reconstruction_loss: 0.1785 - representation_loss: 8.8663\n",
      "Epoch 170/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0432 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 171/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0443 - reconstruction_loss: 0.1786 - representation_loss: 8.8658\n",
      "Epoch 172/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 173/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8661\n",
      "Epoch 174/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0442 - reconstruction_loss: 0.1786 - representation_loss: 8.8657\n",
      "Epoch 175/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8668\n",
      "Epoch 176/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0432 - reconstruction_loss: 0.1786 - representation_loss: 8.8647\n",
      "Epoch 177/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0442 - reconstruction_loss: 0.1786 - representation_loss: 8.8656\n",
      "Epoch 178/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 179/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 180/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0451 - reconstruction_loss: 0.1785 - representation_loss: 8.8666\n",
      "Epoch 181/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 182/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0448 - reconstruction_loss: 0.1786 - representation_loss: 8.8663\n",
      "Epoch 183/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 184/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 185/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0462 - reconstruction_loss: 0.1786 - representation_loss: 8.8677\n",
      "Epoch 186/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0448 - reconstruction_loss: 0.1785 - representation_loss: 8.8662\n",
      "Epoch 187/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0426 - reconstruction_loss: 0.1786 - representation_loss: 8.8641\n",
      "Epoch 188/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 189/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 190/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1786 - representation_loss: 8.8661\n",
      "Epoch 191/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0454 - reconstruction_loss: 0.1785 - representation_loss: 8.8668\n",
      "Epoch 192/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0459 - reconstruction_loss: 0.1786 - representation_loss: 8.8673\n",
      "Epoch 193/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0434 - reconstruction_loss: 0.1785 - representation_loss: 8.8649\n",
      "Epoch 194/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0451 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 195/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 196/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0450 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 197/400\n",
      "859243/859243 [==============================] - 31s 37us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 198/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 199/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0434 - reconstruction_loss: 0.1786 - representation_loss: 8.8648\n",
      "Epoch 200/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 201/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 202/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1785 - representation_loss: 8.8664\n",
      "Epoch 203/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 204/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0454 - reconstruction_loss: 0.1785 - representation_loss: 8.8668\n",
      "Epoch 205/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0446 - reconstruction_loss: 0.1785 - representation_loss: 8.8660\n",
      "Epoch 206/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0459 - reconstruction_loss: 0.1786 - representation_loss: 8.8673\n",
      "Epoch 207/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0444 - reconstruction_loss: 0.1785 - representation_loss: 8.8659\n",
      "Epoch 208/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0444 - reconstruction_loss: 0.1785 - representation_loss: 8.8658\n",
      "Epoch 209/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 210/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0433 - reconstruction_loss: 0.1786 - representation_loss: 8.8648\n",
      "Epoch 211/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0463 - reconstruction_loss: 0.1786 - representation_loss: 8.8678\n",
      "Epoch 212/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 213/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0439 - reconstruction_loss: 0.1785 - representation_loss: 8.8653\n",
      "Epoch 214/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1785 - representation_loss: 8.8650\n",
      "Epoch 215/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0448 - reconstruction_loss: 0.1785 - representation_loss: 8.8662\n",
      "Epoch 216/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0444 - reconstruction_loss: 0.1785 - representation_loss: 8.8658\n",
      "Epoch 217/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0459 - reconstruction_loss: 0.1785 - representation_loss: 8.8673\n",
      "Epoch 218/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0434 - reconstruction_loss: 0.1786 - representation_loss: 8.8648\n",
      "Epoch 219/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0440 - reconstruction_loss: 0.1785 - representation_loss: 8.8655\n",
      "Epoch 220/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 221/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 222/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 223/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 224/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1785 - representation_loss: 8.8661\n",
      "Epoch 225/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0443 - reconstruction_loss: 0.1785 - representation_loss: 8.8657\n",
      "Epoch 226/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 227/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0435 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 228/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0427 - reconstruction_loss: 0.1786 - representation_loss: 8.8641\n",
      "Epoch 229/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0433 - reconstruction_loss: 0.1785 - representation_loss: 8.8648\n",
      "Epoch 230/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 231/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0431 - reconstruction_loss: 0.1785 - representation_loss: 8.8645\n",
      "Epoch 232/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0444 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 233/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 234/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0424 - reconstruction_loss: 0.1785 - representation_loss: 8.8638\n",
      "Epoch 235/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8651\n",
      "Epoch 236/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0441 - reconstruction_loss: 0.1785 - representation_loss: 8.8656\n",
      "Epoch 237/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 238/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 239/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0442 - reconstruction_loss: 0.1786 - representation_loss: 8.8656\n",
      "Epoch 240/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0450 - reconstruction_loss: 0.1786 - representation_loss: 8.8665\n",
      "Epoch 241/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1785 - representation_loss: 8.8651\n",
      "Epoch 242/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0429 - reconstruction_loss: 0.1785 - representation_loss: 8.8643\n",
      "Epoch 243/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0435 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 244/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0455 - reconstruction_loss: 0.1785 - representation_loss: 8.8669\n",
      "Epoch 245/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0462 - reconstruction_loss: 0.1786 - representation_loss: 8.8676\n",
      "Epoch 246/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1785 - representation_loss: 8.8663\n",
      "Epoch 247/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 248/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0415 - reconstruction_loss: 0.1785 - representation_loss: 8.8630\n",
      "Epoch 249/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0433 - reconstruction_loss: 0.1785 - representation_loss: 8.8647\n",
      "Epoch 250/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0457 - reconstruction_loss: 0.1786 - representation_loss: 8.8671\n",
      "Epoch 251/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0443 - reconstruction_loss: 0.1786 - representation_loss: 8.8657\n",
      "Epoch 252/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 253/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0435 - reconstruction_loss: 0.1786 - representation_loss: 8.8649\n",
      "Epoch 254/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1785 - representation_loss: 8.8650\n",
      "Epoch 255/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 256/400\n",
      "859243/859243 [==============================] - 31s 37us/sample - loss: 9.0432 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 257/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0451 - reconstruction_loss: 0.1785 - representation_loss: 8.8665\n",
      "Epoch 258/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0441 - reconstruction_loss: 0.1785 - representation_loss: 8.8656\n",
      "Epoch 259/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8652\n",
      "Epoch 260/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0461 - reconstruction_loss: 0.1785 - representation_loss: 8.8675\n",
      "Epoch 261/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0429 - reconstruction_loss: 0.1786 - representation_loss: 8.8644\n",
      "Epoch 262/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0455 - reconstruction_loss: 0.1785 - representation_loss: 8.8669\n",
      "Epoch 263/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8671\n",
      "Epoch 264/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 265/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0428 - reconstruction_loss: 0.1785 - representation_loss: 8.8643\n",
      "Epoch 266/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 267/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0428 - reconstruction_loss: 0.1785 - representation_loss: 8.8642\n",
      "Epoch 268/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0433 - reconstruction_loss: 0.1785 - representation_loss: 8.8648\n",
      "Epoch 269/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 270/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0440 - reconstruction_loss: 0.1785 - representation_loss: 8.8654\n",
      "Epoch 271/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8671\n",
      "Epoch 272/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 273/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1785 - representation_loss: 8.8667\n",
      "Epoch 274/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1785 - representation_loss: 8.8659\n",
      "Epoch 275/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0435 - reconstruction_loss: 0.1785 - representation_loss: 8.8650\n",
      "Epoch 276/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 277/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0431 - reconstruction_loss: 0.1785 - representation_loss: 8.8645\n",
      "Epoch 278/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8652\n",
      "Epoch 279/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0455 - reconstruction_loss: 0.1786 - representation_loss: 8.8669\n",
      "Epoch 280/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 281/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8652\n",
      "Epoch 282/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0453 - reconstruction_loss: 0.1785 - representation_loss: 8.8668\n",
      "Epoch 283/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0452 - reconstruction_loss: 0.1785 - representation_loss: 8.8667\n",
      "Epoch 284/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0449 - reconstruction_loss: 0.1786 - representation_loss: 8.8664\n",
      "Epoch 285/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1785 - representation_loss: 8.8659\n",
      "Epoch 286/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0464 - reconstruction_loss: 0.1785 - representation_loss: 8.8678\n",
      "Epoch 287/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0456 - reconstruction_loss: 0.1786 - representation_loss: 8.8670\n",
      "Epoch 288/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0441 - reconstruction_loss: 0.1785 - representation_loss: 8.8655\n",
      "Epoch 289/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8646\n",
      "Epoch 290/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0430 - reconstruction_loss: 0.1786 - representation_loss: 8.8644\n",
      "Epoch 291/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0451 - reconstruction_loss: 0.1786 - representation_loss: 8.8665\n",
      "Epoch 292/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0431 - reconstruction_loss: 0.1786 - representation_loss: 8.8645\n",
      "Epoch 293/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0435 - reconstruction_loss: 0.1785 - representation_loss: 8.8650\n",
      "Epoch 294/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0432 - reconstruction_loss: 0.1785 - representation_loss: 8.8646\n",
      "Epoch 295/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0452 - reconstruction_loss: 0.1785 - representation_loss: 8.8667\n",
      "Epoch 296/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0430 - reconstruction_loss: 0.1785 - representation_loss: 8.8645\n",
      "Epoch 297/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0433 - reconstruction_loss: 0.1785 - representation_loss: 8.8648\n",
      "Epoch 298/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0448 - reconstruction_loss: 0.1785 - representation_loss: 8.8662\n",
      "Epoch 299/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0451 - reconstruction_loss: 0.1786 - representation_loss: 8.8665\n",
      "Epoch 300/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1786 - representation_loss: 8.8650\n",
      "Epoch 301/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1785 - representation_loss: 8.8659\n",
      "Epoch 302/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0460 - reconstruction_loss: 0.1786 - representation_loss: 8.8674\n",
      "Epoch 303/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0454 - reconstruction_loss: 0.1785 - representation_loss: 8.8669\n",
      "Epoch 304/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0450 - reconstruction_loss: 0.1785 - representation_loss: 8.8664\n",
      "Epoch 305/400\n",
      "859243/859243 [==============================] - 31s 37us/sample - loss: 9.0454 - reconstruction_loss: 0.1785 - representation_loss: 8.8669\n",
      "Epoch 306/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0441 - reconstruction_loss: 0.1785 - representation_loss: 8.8656\n",
      "Epoch 307/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 308/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0457 - reconstruction_loss: 0.1785 - representation_loss: 8.8671\n",
      "Epoch 309/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0434 - reconstruction_loss: 0.1785 - representation_loss: 8.8649\n",
      "Epoch 310/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0421 - reconstruction_loss: 0.1786 - representation_loss: 8.8635\n",
      "Epoch 311/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0439 - reconstruction_loss: 0.1786 - representation_loss: 8.8653\n",
      "Epoch 312/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0449 - reconstruction_loss: 0.1786 - representation_loss: 8.8663\n",
      "Epoch 313/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0444 - reconstruction_loss: 0.1785 - representation_loss: 8.8659\n",
      "Epoch 314/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 315/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0441 - reconstruction_loss: 0.1786 - representation_loss: 8.8655\n",
      "Epoch 316/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0447 - reconstruction_loss: 0.1785 - representation_loss: 8.8661\n",
      "Epoch 317/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0436 - reconstruction_loss: 0.1785 - representation_loss: 8.8651\n",
      "Epoch 318/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 319/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0442 - reconstruction_loss: 0.1785 - representation_loss: 8.8657\n",
      "Epoch 320/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0452 - reconstruction_loss: 0.1785 - representation_loss: 8.8667\n",
      "Epoch 321/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1785 - representation_loss: 8.8650\n",
      "Epoch 322/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0452 - reconstruction_loss: 0.1785 - representation_loss: 8.8667\n",
      "Epoch 323/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0450 - reconstruction_loss: 0.1785 - representation_loss: 8.8665\n",
      "Epoch 324/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0446 - reconstruction_loss: 0.1785 - representation_loss: 8.8660\n",
      "Epoch 325/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8651\n",
      "Epoch 326/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0457 - reconstruction_loss: 0.1785 - representation_loss: 8.8672\n",
      "Epoch 327/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0440 - reconstruction_loss: 0.1785 - representation_loss: 8.8655\n",
      "Epoch 328/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0451 - reconstruction_loss: 0.1786 - representation_loss: 8.8666\n",
      "Epoch 329/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0429 - reconstruction_loss: 0.1785 - representation_loss: 8.8644\n",
      "Epoch 330/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0443 - reconstruction_loss: 0.1785 - representation_loss: 8.8657\n",
      "Epoch 331/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0458 - reconstruction_loss: 0.1786 - representation_loss: 8.8673\n",
      "Epoch 332/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8651\n",
      "Epoch 333/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0444 - reconstruction_loss: 0.1786 - representation_loss: 8.8658\n",
      "Epoch 334/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 335/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0433 - reconstruction_loss: 0.1785 - representation_loss: 8.8648\n",
      "Epoch 336/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0446 - reconstruction_loss: 0.1785 - representation_loss: 8.8660\n",
      "Epoch 337/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1785 - representation_loss: 8.8653\n",
      "Epoch 338/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0446 - reconstruction_loss: 0.1785 - representation_loss: 8.8661\n",
      "Epoch 339/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0457 - reconstruction_loss: 0.1786 - representation_loss: 8.8671\n",
      "Epoch 340/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0447 - reconstruction_loss: 0.1785 - representation_loss: 8.8662\n",
      "Epoch 341/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0432 - reconstruction_loss: 0.1785 - representation_loss: 8.8646\n",
      "Epoch 342/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0451 - reconstruction_loss: 0.1785 - representation_loss: 8.8666\n",
      "Epoch 343/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0443 - reconstruction_loss: 0.1785 - representation_loss: 8.8657\n",
      "Epoch 344/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0449 - reconstruction_loss: 0.1785 - representation_loss: 8.8664\n",
      "Epoch 345/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0452 - reconstruction_loss: 0.1786 - representation_loss: 8.8667\n",
      "Epoch 346/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0456 - reconstruction_loss: 0.1785 - representation_loss: 8.8671\n",
      "Epoch 347/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0438 - reconstruction_loss: 0.1785 - representation_loss: 8.8653\n",
      "Epoch 348/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0449 - reconstruction_loss: 0.1785 - representation_loss: 8.8664\n",
      "Epoch 349/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0429 - reconstruction_loss: 0.1785 - representation_loss: 8.8644\n",
      "Epoch 350/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0457 - reconstruction_loss: 0.1786 - representation_loss: 8.8672\n",
      "Epoch 351/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1785 - representation_loss: 8.8654\n",
      "Epoch 352/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0451 - reconstruction_loss: 0.1785 - representation_loss: 8.8665\n",
      "Epoch 353/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0442 - reconstruction_loss: 0.1785 - representation_loss: 8.8657\n",
      "Epoch 354/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0446 - reconstruction_loss: 0.1785 - representation_loss: 8.8661\n",
      "Epoch 355/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0450 - reconstruction_loss: 0.1785 - representation_loss: 8.8665\n",
      "Epoch 356/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0446 - reconstruction_loss: 0.1786 - representation_loss: 8.8660\n",
      "Epoch 357/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 358/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0461 - reconstruction_loss: 0.1785 - representation_loss: 8.8675\n",
      "Epoch 359/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0434 - reconstruction_loss: 0.1785 - representation_loss: 8.8648\n",
      "Epoch 360/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0434 - reconstruction_loss: 0.1785 - representation_loss: 8.8649\n",
      "Epoch 361/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0432 - reconstruction_loss: 0.1785 - representation_loss: 8.8646\n",
      "Epoch 362/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0426 - reconstruction_loss: 0.1785 - representation_loss: 8.8641\n",
      "Epoch 363/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0445 - reconstruction_loss: 0.1785 - representation_loss: 8.8659\n",
      "Epoch 364/400\n",
      "859243/859243 [==============================] - 32s 37us/sample - loss: 9.0448 - reconstruction_loss: 0.1785 - representation_loss: 8.8663\n",
      "Epoch 365/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0440 - reconstruction_loss: 0.1786 - representation_loss: 8.8654\n",
      "Epoch 366/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0434 - reconstruction_loss: 0.1785 - representation_loss: 8.8648\n",
      "Epoch 367/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8652\n",
      "Epoch 368/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0424 - reconstruction_loss: 0.1785 - representation_loss: 8.8639\n",
      "Epoch 369/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0424 - reconstruction_loss: 0.1785 - representation_loss: 8.8639\n",
      "Epoch 370/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0450 - reconstruction_loss: 0.1785 - representation_loss: 8.8665\n",
      "Epoch 371/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0444 - reconstruction_loss: 0.1785 - representation_loss: 8.8658\n",
      "Epoch 372/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8651\n",
      "Epoch 373/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0442 - reconstruction_loss: 0.1785 - representation_loss: 8.8657\n",
      "Epoch 374/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0441 - reconstruction_loss: 0.1785 - representation_loss: 8.8655\n",
      "Epoch 375/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0429 - reconstruction_loss: 0.1786 - representation_loss: 8.8644\n",
      "Epoch 376/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0439 - reconstruction_loss: 0.1785 - representation_loss: 8.8653\n",
      "Epoch 377/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0450 - reconstruction_loss: 0.1785 - representation_loss: 8.8664\n",
      "Epoch 378/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1785 - representation_loss: 8.8650\n",
      "Epoch 379/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0456 - reconstruction_loss: 0.1785 - representation_loss: 8.8670\n",
      "Epoch 380/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0442 - reconstruction_loss: 0.1785 - representation_loss: 8.8656\n",
      "Epoch 381/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0432 - reconstruction_loss: 0.1785 - representation_loss: 8.8647\n",
      "Epoch 382/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0446 - reconstruction_loss: 0.1785 - representation_loss: 8.8661\n",
      "Epoch 383/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0432 - reconstruction_loss: 0.1786 - representation_loss: 8.8647\n",
      "Epoch 384/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0458 - reconstruction_loss: 0.1786 - representation_loss: 8.8672\n",
      "Epoch 385/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0431 - reconstruction_loss: 0.1785 - representation_loss: 8.8646\n",
      "Epoch 386/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0426 - reconstruction_loss: 0.1785 - representation_loss: 8.8641\n",
      "Epoch 387/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1785 - representation_loss: 8.8651\n",
      "Epoch 388/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0466 - reconstruction_loss: 0.1785 - representation_loss: 8.8681\n",
      "Epoch 389/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0432 - reconstruction_loss: 0.1785 - representation_loss: 8.8647\n",
      "Epoch 390/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0448 - reconstruction_loss: 0.1785 - representation_loss: 8.8663\n",
      "Epoch 391/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0444 - reconstruction_loss: 0.1786 - representation_loss: 8.8659\n",
      "Epoch 392/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0436 - reconstruction_loss: 0.1785 - representation_loss: 8.8651\n",
      "Epoch 393/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0439 - reconstruction_loss: 0.1785 - representation_loss: 8.8654\n",
      "Epoch 394/400\n",
      "859243/859243 [==============================] - 31s 36us/sample - loss: 9.0453 - reconstruction_loss: 0.1785 - representation_loss: 8.8668\n",
      "Epoch 395/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0445 - reconstruction_loss: 0.1785 - representation_loss: 8.8660\n",
      "Epoch 396/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0433 - reconstruction_loss: 0.1785 - representation_loss: 8.8648\n",
      "Epoch 397/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0435 - reconstruction_loss: 0.1785 - representation_loss: 8.8649\n",
      "Epoch 398/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0437 - reconstruction_loss: 0.1786 - representation_loss: 8.8652\n",
      "Epoch 399/400\n",
      "859243/859243 [==============================] - 30s 35us/sample - loss: 9.0439 - reconstruction_loss: 0.1785 - representation_loss: 8.8653\n",
      "Epoch 400/400\n",
      "859243/859243 [==============================] - 31s 37us/sample - loss: 9.0432 - reconstruction_loss: 0.1785 - representation_loss: 8.8647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef1818c860>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit([X_train, y_train], X_train, epochs=400, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = mu_encoder.predict(X_train)\n",
    "z_test = mu_encoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fef172f2470>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(\n",
    "    z_train[y_train == 0, 0][0:10000],\n",
    "    z_train[y_train == 0, 1][0:10000],\n",
    "    color=\"DarkBlue\",\n",
    "    alpha=0.75,\n",
    "    s=1\n",
    ")\n",
    "\n",
    "ax.scatter(\n",
    "    z_train[y_train == 1, 0][0:10000],\n",
    "    z_train[y_train == 1, 1][0:10000],\n",
    "    color=\"DarkRed\",\n",
    "    alpha=0.25,\n",
    "    s=1    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics as skmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calsaverini/dev/analysis/survival/second_order/VAE/venv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "clf.fit(z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_pred = clf.predict_proba(z_test)\n",
    "y_pred = clf.predict(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85    274794\n",
      "           1       0.39      0.02      0.03     93454\n",
      "\n",
      "   micro avg       0.74      0.74      0.74    368248\n",
      "   macro avg       0.57      0.50      0.44    368248\n",
      "weighted avg       0.66      0.74      0.64    368248\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.74768008, 0.38634098]),\n",
       " array([0.99104056, 0.0165857 ]),\n",
       " array([0.85232931, 0.03180596]),\n",
       " array([274794,  93454]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(skmetrics.classification_report(y_test, y_pred))\n",
    "skmetrics.precision_recall_fscore_support(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5796613819733163"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmetrics.roc_auc_score(y_test, s_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calsaverini/dev/analysis/survival/second_order/VAE/venv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_2 = RandomForestClassifier(n_jobs=-1)\n",
    "clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89    274794\n",
      "           1       0.71      0.53      0.60     93454\n",
      "\n",
      "   micro avg       0.82      0.82      0.82    368248\n",
      "   macro avg       0.78      0.73      0.75    368248\n",
      "weighted avg       0.81      0.82      0.82    368248\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.85222677, 0.70533036]),\n",
       " array([0.92492194, 0.5284204 ]),\n",
       " array([0.88708754, 0.60419165]),\n",
       " array([274794,  93454]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_pred = clf_2.predict_proba(X_test)\n",
    "y_pred = clf_2.predict(X_test)\n",
    "print(skmetrics.classification_report(y_test, y_pred))\n",
    "skmetrics.precision_recall_fscore_support(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7995045667135877"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skmetrics.roc_auc_score(y_test, s_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = MiniBatchKMeans(n_clusters=2)\n",
    "labels = cls.fit_predict(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.85    274794\n",
      "           1       0.27      0.00      0.01     93454\n",
      "\n",
      "   micro avg       0.74      0.74      0.74    368248\n",
      "   macro avg       0.51      0.50      0.43    368248\n",
      "weighted avg       0.63      0.74      0.64    368248\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(skmetrics.classification_report(y_test, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrix(actual_vector=y_test.values, predict_vector=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict      0            1            \n",
      "Actual\n",
      "0            273845       949          \n",
      "\n",
      "1            93101        353          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Overall Statistics : \n",
      "\n",
      "95% CI                                                            (0.74319,0.74601)\n",
      "AUNP                                                              0.50016\n",
      "AUNU                                                              0.50016\n",
      "Bennett S                                                         0.4892\n",
      "CBA                                                               0.37503\n",
      "Chi-Squared                                                       2.07485\n",
      "Chi-Squared DF                                                    1\n",
      "Conditional Entropy                                               0.03388\n",
      "Cramer V                                                          0.00237\n",
      "Cross Entropy                                                     2.07055\n",
      "Gwet AC1                                                          0.67079\n",
      "Hamming Loss                                                      0.2554\n",
      "Joint Entropy                                                     0.8511\n",
      "KL Divergence                                                     1.25333\n",
      "Kappa                                                             0.00048\n",
      "Kappa 95% CI                                                      (-0.00503,0.00599)\n",
      "Kappa No Prevalence                                               0.4892\n",
      "Kappa Standard Error                                              0.00281\n",
      "Kappa Unbiased                                                    -0.1391\n",
      "Lambda A                                                          0.0\n",
      "Lambda B                                                          0.0\n",
      "Mutual Information                                                0.0\n",
      "NIR                                                               0.74622\n",
      "Overall ACC                                                       0.7446\n",
      "Overall CEN                                                       0.37595\n",
      "Overall J                                                         (0.7481,0.37405)\n",
      "Overall MCC                                                       0.00237\n",
      "Overall MCEN                                                      0.27276\n",
      "Overall RACC                                                      0.74448\n",
      "Overall RACCU                                                     0.77579\n",
      "P-Value                                                           None\n",
      "PPV Macro                                                         0.5087\n",
      "PPV Micro                                                         0.7446\n",
      "Pearson C                                                         0.00237\n",
      "Phi-Squared                                                       1e-05\n",
      "RCI                                                               0.0\n",
      "RR                                                                184124.0\n",
      "Reference Entropy                                                 0.81721\n",
      "Response Entropy                                                  0.03389\n",
      "SOA1(Landis & Koch)                                               Slight\n",
      "SOA2(Fleiss)                                                      Poor\n",
      "SOA3(Altman)                                                      Poor\n",
      "SOA4(Cicchetti)                                                   Poor\n",
      "Scott PI                                                          -0.1391\n",
      "Standard Error                                                    0.00072\n",
      "TPR Macro                                                         0.50016\n",
      "TPR Micro                                                         0.7446\n",
      "Zero-one Loss                                                     94050\n",
      "\n",
      "Class Statistics :\n",
      "\n",
      "Classes                                                           0             1             \n",
      "ACC(Accuracy)                                                     0.7446        0.7446        \n",
      "AM(Difference between automatic and manual classification)        92152         -92152        \n",
      "AUC(Area under the roc curve)                                     0.50016       0.50016       \n",
      "AUCI(AUC value interpretation)                                    Poor          Poor          \n",
      "BCD(Bray-Curtis dissimilarity)                                    0.12512       0.12512       \n",
      "BM(Informedness or bookmaker informedness)                        0.00032       0.00032       \n",
      "CEN(Confusion entropy)                                            0.41796       0.09149       \n",
      "DOR(Diagnostic odds ratio)                                        1.0941        1.0941        \n",
      "DP(Discriminant power)                                            0.02153       0.02153       \n",
      "DPI(Discriminant power interpretation)                            Poor          Poor          \n",
      "ERR(Error rate)                                                   0.2554        0.2554        \n",
      "F0.5(F0.5 score)                                                  0.78575       0.01789       \n",
      "F1(F1 score - harmonic mean of precision and sensitivity)         0.85345       0.00745       \n",
      "F2(F2 score)                                                      0.93391       0.00471       \n",
      "FDR(False discovery rate)                                         0.25372       0.72888       \n",
      "FN(False negative/miss/type 2 error)                              949           93101         \n",
      "FNR(Miss rate or false negative rate)                             0.00345       0.99622       \n",
      "FOR(False omission rate)                                          0.72888       0.25372       \n",
      "FP(False positive/type 1 error/false alarm)                       93101         949           \n",
      "FPR(Fall-out or false positive rate)                              0.99622       0.00345       \n",
      "G(G-measure geometric mean of precision and sensitivity)          0.86238       0.032         \n",
      "GI(Gini index)                                                    0.00032       0.00032       \n",
      "GM(G-mean geometric mean of specificity and sensitivity)          0.06135       0.06135       \n",
      "IBA(Index of balanced accuracy)                                   0.0075        3e-05         \n",
      "IS(Information score)                                             0.00012       0.09536       \n",
      "J(Jaccard index)                                                  0.74436       0.00374       \n",
      "LS(Lift score)                                                    1.00008       1.06833       \n",
      "MCC(Matthews correlation coefficient)                             0.00237       0.00237       \n",
      "MCEN(Modified confusion entropy)                                  0.52386       0.08647       \n",
      "MK(Markedness)                                                    0.0174        0.0174        \n",
      "N(Condition negative)                                             93454         274794        \n",
      "NLR(Negative likelihood ratio)                                    0.91429       0.99968       \n",
      "NPV(Negative predictive value)                                    0.27112       0.74628       \n",
      "OP(Optimized precision)                                           -0.24785      -0.24785      \n",
      "P(Condition positive or support)                                  274794        93454         \n",
      "PLR(Positive likelihood ratio)                                    1.00032       1.09375       \n",
      "PLRI(Positive likelihood ratio interpretation)                    Poor          Poor          \n",
      "POP(Population)                                                   368248        368248        \n",
      "PPV(Precision or positive predictive value)                       0.74628       0.27112       \n",
      "PRE(Prevalence)                                                   0.74622       0.25378       \n",
      "RACC(Random accuracy)                                             0.74358       0.0009        \n",
      "RACCU(Random accuracy unbiased)                                   0.75924       0.01655       \n",
      "TN(True negative/correct rejection)                               353           273845        \n",
      "TNR(Specificity or true negative rate)                            0.00378       0.99655       \n",
      "TON(Test outcome negative)                                        1302          366946        \n",
      "TOP(Test outcome positive)                                        366946        1302          \n",
      "TP(True positive/hit)                                             273845        353           \n",
      "TPR(Sensitivity, recall, hit rate, or true positive rate)         0.99655       0.00378       \n",
      "Y(Youden index)                                                   0.00032       0.00032       \n",
      "dInd(Distance index)                                              0.99623       0.99623       \n",
      "sInd(Similarity index)                                            0.29556       0.29556       \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
